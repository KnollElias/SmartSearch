{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_to_analyze(path):\n",
    "    image = convert_from_path(path, dpi=75)\n",
    "    image = np.array(image)\n",
    "    #image = format_image(image)\n",
    "    # Convert RGB to grayscale (monochrome)\n",
    "    if image.shape[-1] == 3:  # Ensure it's an RGB image\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "    \n",
    "    image = tf.convert_to_tensor(image, dtype=tf.uint8) \n",
    "    \n",
    "    # Set the target height and width (adjust as needed)\n",
    "    target_size = (1241, 1000)  # Example target width and height\n",
    "\n",
    "    # Resize all images\n",
    "    image_resized = tf.image.resize(image, target_size)\n",
    "    result = tf.data.Dataset.from_tensor_slices({ \"image\": image_resized})\n",
    "    return result\n",
    "\n",
    "def format_image(data):        \n",
    "    image = data[\"image\"]\n",
    "    image = tf.reshape(image, [-1])\n",
    "    image = tf.cast(image, 'float32')\n",
    "    image = image / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_codes = {\"ECG_GCG\" : 0, \"ECG_FCG\" : 1, \"ECG_GCG_EC\" : 2, \"GCG_GCG_GCG\" : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = load_model(\"model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/jonhe/OneDrive/Documents/Hackathons/AEC Construction 2025/Data/ECG_FCG/DF2.10.pdf'\n",
    "\n",
    "input = load_pdf_to_analyze(path)\n",
    "\n",
    "input_formatted = input.map(format_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=TensorSpec(shape=(1241000,), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "\n",
    "# input_formatted = input_formatted.batch(batch_size)  # Ensure batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in input_formatted.take(1):\n",
    "#     print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1241000)\n"
     ]
    }
   ],
   "source": [
    "print(model.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in input_formatted.take(1):\n",
    "    batch = tf.expand_dims(batch, axis=0)  # Convert shape (1241000,) â†’ (1, 1241000)\n",
    "    model(batch)  # Now it matches (None, 1241000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1241000)\n",
      "Model Outputs: [[0.012424   0.0205664  0.92927426 0.03773531]]\n"
     ]
    }
   ],
   "source": [
    "for batch in input_formatted.take(1):  # Take a single batch\n",
    "    batch = tf.expand_dims(batch, axis=0)  # Add batch dimension (1, 1241000)\n",
    "    #print(batch.shape)  # Should be (1, 1241000)\n",
    "    outputs=model(batch)  # Pass the tensor batch to the model\n",
    "\n",
    "    print(\"Model Outputs:\", outputs.numpy())  # Convert tensor to NumPy for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category is ECG_GCG_EC.\n"
     ]
    }
   ],
   "source": [
    "item_nr = outputs.numpy()[0].argmax()\n",
    "\n",
    "print('The category is ' + list(class_codes.keys())[item_nr] +'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
